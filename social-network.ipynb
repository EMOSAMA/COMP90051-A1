{
 "cells": [
  {
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "from typing import List, Any, Union\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import math\n",
    "import copy as cp"
   ],
   "execution_count": 36,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "def buildGraph(data):\n",
    "    graph = {}\n",
    "    for line in data:\n",
    "        line = re.sub(r\"(?<=\\d)\\n\", \"\", line)\n",
    "        pattern = re.compile(\"(?<=\\d)\\t(?=\\d)\")\n",
    "        line = re.split(pattern, line)\n",
    "        graph[line[0]] = line[1:]\n",
    "    return graph\n",
    "\n",
    "def reFormatTestData(data):\n",
    "    format_data = []\n",
    "    for line in data:\n",
    "        line = re.sub(r\"(?<=\\d)\\n\", \"\", line)\n",
    "        pattern = re.compile(\"(?<=\\d)\\t(?=\\d)\")\n",
    "        line = re.split(pattern, line)\n",
    "        line[0] = int(line[0])\n",
    "        format_data.append(line)\n",
    "    return format_data\n",
    "\n",
    "def ReformatTrainData(data):\n",
    "    format_data = []\n",
    "    for line in data:\n",
    "        line = re.sub(r\"(?<=\\d)\\n\", \"\", line)\n",
    "        pattern = re.compile(\"(?<=\\d)\\t(?=\\d)\")\n",
    "        line = re.split(pattern, line)\n",
    "        line[0] = int(line[0])\n",
    "        format_data.append(line)\n",
    "    return format_data\n",
    "\n",
    "# read train data\n",
    "file_dir = 'comp90051-2020-sem2-proj1/'\n",
    "file_name = \"SmallTrain.txt\"\n",
    "\n",
    "global graph,train_set,test_set\n",
    "with open(os.path.join(file_dir, file_name)) as f:\n",
    "    graph = f.readlines()\n",
    "    graph = buildGraph(graph)\n",
    "    train_set = ReformatTrainData(graph)\n",
    "\n",
    "# read test data\n",
    "test_name = \"SmallTest.txt\"\n",
    "with open(os.path.join(file_dir, test_name)) as f:\n",
    "    f.readline()\n",
    "    test_set = f.readlines()\n",
    "    test_set = reFormatTestData(test_set)\n"
   ],
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "print(len(graph))\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "#print(type(test_set))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Feature Extraction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "### Feature Extraction\n",
    "'''\n",
    "# Combin in and out\n",
    "# input:str,dic\n",
    "def getNeighbors(node, graph):\n",
    "    follows = GetFollows(node, graph)\n",
    "    fans = GetFans(node, graph)\n",
    "    neighbors = follows.union(fans)\n",
    "    return neighbors\n",
    "\n",
    "def getNeighborsNumber(node, graph):\n",
    "    follows = GetFollows(node, graph)\n",
    "    fans = GetFans(node, graph)\n",
    "    neighbors = follows.union(fans)\n",
    "    return len(neighbors)\n",
    "\n",
    "# out\n",
    "def GetFollows(node, graph):\n",
    "    follows = set()\n",
    "    try:\n",
    "        for item in graph[node]:\n",
    "            follows.add(item)\n",
    "        return follows\n",
    "    except:\n",
    "        return follows\n",
    "\n",
    "# in\n",
    "def GetFans(node, graph):\n",
    "    fans = set()\n",
    "    for key, value in graph.items():\n",
    "        if node in value:\n",
    "            fans.add(key)\n",
    "    return fans\n",
    "\n",
    "# Common Neighbors in Level 1\n",
    "# numCommonCoauthor(x,y)\n",
    "def commonNeighborsLevel1(a, b, graph):\n",
    "    neighbors_a = getNeighbors(a, graph)\n",
    "    neighbors_b = getNeighbors(b, graph)\n",
    "    return len(neighbors_a.intersection(neighbors_b))\n",
    "\n",
    "#Jaccard’s Coefficient\n",
    "#两个人共同邻居的数量在他们所有好友数量中占比\n",
    "def GetJaccardCoefficient(user_X,user_y,graph):\n",
    "    neighbors_x = getNeighbors(user_X, graph)\n",
    "    neighbors_y = getNeighbors(user_y, graph)\n",
    "    CommonNeighbors=len(neighbors_x.intersection(neighbors_y))\n",
    "    AllNeighborss=len(neighbors_x.union(neighbors_y))\n",
    "    if AllNeighborss>=0:\n",
    "        JaccardCoefficient=CommonNeighbors/AllNeighborss\n",
    "    return JaccardCoefficient\n",
    "\n",
    "#Adamic\n",
    "#邻居的邻居数量越少，就越凸显它作为“中间人”的重要性，毕竟一共只认识那么少人，却恰好是x，y的好朋友\n",
    "\n",
    "def GetAdamic(user_X,user_y,graph):\n",
    "    neighbors_x = getNeighbors(user_X, graph)\n",
    "    neighbors_y = getNeighbors(user_y, graph)\n",
    "    CommonNeighbors=neighbors_x.intersection(neighbors_y)\n",
    "    Adamic=0\n",
    "    for commonNeighbor in CommonNeighbors:\n",
    "        NeighborOfCommonNeighbor=getNeighborsNumber(commonNeighbor,graph)\n",
    "        if NeighborOfCommonNeighbor!=0 and NeighborOfCommonNeighbor!=1:\n",
    "            Adamic+=1/math.log(NeighborOfCommonNeighbor)\n",
    "\n",
    "    return Adamic\n",
    "\n",
    "#sumCoauthor\n",
    "\n",
    "\n",
    "# Common Neighbors in Level 2\n",
    "def commonNeighborsLevel2(a, b, graph):\n",
    "    score = 0\n",
    "    follows_a = GetFollows(a, graph)\n",
    "    if follows_a:\n",
    "        for node in follows_a:\n",
    "            score += commonNeighborsLevel1(b, node, graph)\n",
    "        return float(score / len(follows_a))\n",
    "    else:\n",
    "        return 0"
   ],
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "debugging methods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "'''\n",
    "def getTestFeatures(record: list) -> list:\n",
    "    node= [record[0],GetAdamic(record[1], record[-1], graph)]\n",
    "    #print(node)\n",
    "    return node\n",
    "features=[]\n",
    "for record in test_set:\n",
    "    features.append(getTestFeatures(record))\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Feature Extraction\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feature Extraction\n",
    "def getTestFeatures(record: list) -> list:\n",
    "    node= [record[0],len(GetFans(record[1],graph)),len(GetFollows(record[1],graph)),len(GetFans(record[-1],graph)),len(GetFollows(record[-1],graph)),commonNeighborsLevel1(record[1], record[-1], graph)]\n",
    "    #print(node)\n",
    "    return node\n",
    "features=[]\n",
    "for record in test_set:\n",
    "    features.append(getTestFeatures(record))\n",
    "\n",
    "#print(features)\n",
    "title = [\"Id\", \"InSource\", \"OutSource\", \"InSink\", \"OutSink\", \"CommonNeighboursLevel1\"]\n",
    "test_pd = pd.DataFrame(columns=title, data=features)\n",
    "test_pd.to_csv('test_set_features.csv', encoding='utf-8')\n",
    "\n",
    "test_set.clear()\n",
    "features.clear()\n",
    "#test_pd.clear()"
   ],
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "following can be ignored.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('4', '1', 1), ('4', '3', 1), ('4', '5', 1), ('2', '3', 1), ('1', '2', 1)]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "### Train Set Building\n",
    "'''\n",
    "def buildPositiveTrainSet(temp_graph):\n",
    "    train_set_positive = set()\n",
    "    # Positive train data\n",
    "    for key in temp_graph:\n",
    "        for each in graph[key]:\n",
    "            train_set_positive.add((key,each,1)) #setting category of positive as 1 eg:(seed,followee1,1)\n",
    "    return list(train_set_positive)\n",
    "\n",
    "train_set_positive = buildPositiveTrainSet(graph)\n",
    "print(train_set_positive)\n",
    "print(len(train_set_positive))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "def getTrainFeatures(record):\n",
    "    node= [record[0],len(GetFans(record[1],graph)),len(GetFollows(record[1],graph)),len(GetFans(record[-1],graph)),len(GetFollows(record[-1],graph)),commonNeighborsLevel1(record[1], record[-1], graph),record[-1]]\n",
    "    return node\n",
    "\n",
    "print(train_set)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "title = [\"Id\", \"InSource\", \"OutSource\", \"InSink\", \"OutSink\", \"CommonNeighboursLevel1\"]\n",
    "test_pd = pd.DataFrame(columns=title, data=features)\n",
    "test_pd.to_csv('./train_set_positive_features.csv', encoding='utf-8')\n",
    "\n",
    "features.clear()\n",
    "test_pd.clear()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def buildNegativeTrainSet(graph):\n",
    "    train_set_negative = set()\n",
    "    # Positive train data\n",
    "    train_set_negative = set()\n",
    "    for key in graph:\n",
    "        for each in graph[key]:\n",
    "            if((each,key) not in train_set_positive):\n",
    "                train_set_negative.add((each,key,0))\n",
    "\n",
    "    keys = list(graph.keys())\n",
    "    for i in range(len(keys)-1):\n",
    "        if ((keys[i],keys[i+1]) not in train_set_positive):\n",
    "            train_set_negative.add((keys[i],keys[i+1]))\n",
    "        if ((keys[i+1],keys[i]) not in train_set_positive):\n",
    "            train_set_negative.add((keys[i+1],keys[i]))\n",
    "    return list(train_set_negative)\n",
    "#print(len(train_set_negative))\n",
    "train_set_positive.clear()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "def getTrainFeatures(record):\n",
    "    node= [record[0],len(GetFans(record[1],graph)),len(GetFollows(record[1],graph)),len(GetFans(record[-1],graph)),len(GetFollows(record[-1],graph)),commonNeighborsLevel1(record[1], record[-1], graph),record[-1]]\n",
    "    return node\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "features = pool.map(getTrainFeatures, train_set)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "title = [\"Id\", \"InA\", \"OutA\", \"InB\", \"OutB\", \"CommonNeighboursLevel1\", \"Label\"]\n",
    "test_pd = pd.DataFrame(columns=title, data=features)\n",
    "test_pd.to_csv('./train_set_negatitive_features.csv', encoding='utf-8')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}