{
 "cells": [
  {
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ],
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import math"
   ],
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import os\n",
    "def buildGraph(data):\n",
    "    graph = {}\n",
    "    for line in data:\n",
    "        line = re.sub(r\"(?<=\\d)\\n\", \"\", line)\n",
    "        pattern = re.compile(\"(?<=\\d)\\t(?=\\d)\")\n",
    "        line = re.split(pattern, line)\n",
    "        graph[line[0]] = line[1:]\n",
    "    return graph\n",
    "\n",
    "def reFormatTestData(data):\n",
    "    format_data = []\n",
    "    for line in data:\n",
    "        line = re.sub(r\"(?<=\\d)\\n\", \"\", line)\n",
    "        pattern = re.compile(\"(?<=\\d)\\t(?=\\d)\")\n",
    "        line = re.split(pattern, line)\n",
    "        line[0] = int(line[0])\n",
    "        format_data.append(line)\n",
    "    return format_data\n",
    "\n",
    "# read train data\n",
    "file_dir = 'D:\\COMP90051\\COMP90051-A1\\comp90051-2020-sem2-proj1'\n",
    "file_name = \"SmallTrain.txt\"\n",
    "with open(os.path.join(file_dir, file_name)) as f:\n",
    "    graph = f.readlines()\n",
    "    graph = buildGraph(graph)\n",
    "\n",
    "# read test data\n",
    "test_name = \"SmallTest.txt\"\n",
    "with open(os.path.join(file_dir, test_name)) as f:\n",
    "    f.readline()\n",
    "    test_data = f.readlines()\n",
    "    test_data = reFormatTestData(test_data)\n",
    "\n",
    "print(len(graph))\n",
    "print(len(test_data))"
   ],
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "### Edge Set Building\n",
    "'''\n",
    "def buildEdgeSet(graph):\n",
    "    edge_set = set()\n",
    "    # Positive train data\n",
    "    for key in graph:\n",
    "        for each in graph[key]:\n",
    "            edge_set.add((key,each))\n",
    "    return edge_set\n",
    "\n",
    "edge_set = buildEdgeSet(graph)\n",
    "\n",
    "print(len(edge_set))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# read train data and label\n",
    "file_dir = 'D:\\COMP90051\\COMP90051-A1\\comp90051-2020-sem2-proj1'\n",
    "file_name = \"train_data.csv\"\n",
    "with open(os.path.join(file_dir, file_name)) as f:\n",
    "    f.readline()\n",
    "    train_data = []\n",
    "    data = f.readlines()\n",
    "    for line in data:\n",
    "        line = re.sub(r\"(?<=\\d)\\n\", \"\", line)\n",
    "        pattern = re.compile(\"(?<=\\d)\\t(?=\\d)\")\n",
    "        line = re.split(',', line)\n",
    "        line[0] = int(line[0])\n",
    "        train_data.append(line)\n",
    "\n",
    "file_name = \"train_label.csv\"\n",
    "with open(os.path.join(file_dir, file_name)) as f:\n",
    "    f.readline()\n",
    "    train_label = f.readlines()\n",
    "\n",
    "# read validation data and label\n",
    "file_name = \"validation_data.csv\"\n",
    "with open(os.path.join(file_dir, file_name)) as f:\n",
    "    f.readline()\n",
    "    validation_data = []\n",
    "    data = f.readlines()\n",
    "    for line in data:\n",
    "        line = re.sub(r\"(?<=\\d)\\n\", \"\", line)\n",
    "        pattern = re.compile(\"(?<=\\d)\\t(?=\\d)\")\n",
    "        line = re.split(',', line)\n",
    "        line[0] = int(line[0])\n",
    "        validation_data.append(line)\n",
    "\n",
    "file_name = \"validation_label.csv\"\n",
    "with open(os.path.join(file_dir, file_name)) as f:\n",
    "    f.readline()\n",
    "    validation_label = f.readlines()\n",
    "\n",
    "print(len(train_data))\n",
    "print(train_data[0])\n",
    "print(len(train_label))\n",
    "print(train_label[0])\n",
    "\n",
    "print(len(validation_data))\n",
    "print(validation_data[0])\n",
    "print(len(validation_label))\n",
    "print(validation_label[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n",
      "[0, '2722942', '243804']\n",
      "80000\n",
      "0,1\n",
      "\n",
      "20000\n",
      "[0, '1063358', '421585']\n",
      "20000\n",
      "0,1\n",
      "\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "### Feature Extraction\n",
    "'''\n",
    "\n",
    "'''\n",
    "##顶点度特征\n",
    "'''\n",
    "# feature 1: out,关注的人\n",
    "def getDegreeOut(node, graph):\n",
    "    degreeOut = set()\n",
    "    try:\n",
    "        degreeOut = set(graph[node])\n",
    "        return degreeOut\n",
    "    except:\n",
    "        return degreeOut\n",
    "\n",
    "# feature 2: in 关注我的人\n",
    "def getDegreeIn(node, graph):\n",
    "    degreeIn = set()\n",
    "    for key, value in graph.items():\n",
    "        if node in set(value):\n",
    "            degreeIn.add(key)\n",
    "    return degreeIn\n",
    "\n",
    "# feature3: Combin in and out\n",
    "def getNeighbors(node, graph):\n",
    "    degree_out = getDegreeOut(node, graph)\n",
    "    degree_in = getDegreeIn(node, graph)\n",
    "    neighbors = degree_out.union(degree_in)\n",
    "    return neighbors\n",
    "\n",
    "# feature 4: The Intersection of out and in 就是互关\n",
    "def feature4(a, graph):\n",
    "    out_a = getDegreeOut(a, graph)\n",
    "    in_a = getDegreeIn(a, graph)\n",
    "    return len(out_a.intersection(in_a))\n",
    "\n",
    "\n",
    "'''\n",
    "##共同邻居特征\n",
    "'''\n",
    "# feature 5: Common Neighbours of A and B\n",
    "def commonNeighbors(a, b, graph):\n",
    "    neighbors_a = getNeighbors(a, graph)\n",
    "    neighbors_b = getNeighbors(b, graph)\n",
    "    return len(neighbors_a.intersection(neighbors_b))\n",
    "\n",
    "# feature 6: Common Followees(in) of A and B\n",
    "def commonIn(a, b, graph):\n",
    "    in_a = getDegreeIn(a, graph)\n",
    "    in_b = getDegreeIn(b, graph)\n",
    "    return len(in_a.intersection(in_b))\n",
    "\n",
    "# feature 7: Common Followers(out) of A and B\n",
    "def commonOut(a, b, graph):\n",
    "    out_a = getDegreeOut(a, graph)\n",
    "    out_b = getDegreeOut(b, graph)\n",
    "    return len(out_a.intersection(out_b))\n",
    "\n",
    "'''\n",
    "##邻居总数特征\n",
    "'''\n",
    "# feature 8: Union Followers(out) of A and B\n",
    "def unionOut(a, b, graph):\n",
    "    out_a = getDegreeOut(a, graph)\n",
    "    out_b = getDegreeOut(b, graph)\n",
    "    return len(out_a.union(out_b))\n",
    "\n",
    "# feature 9: Union Followees(in) of A and B\n",
    "def unionIn(a, b, graph):\n",
    "    in_a = getDegreeIn(a, graph)\n",
    "    in_b = getDegreeIn(b, graph)\n",
    "    return len(in_a.union(in_b))\n",
    "\n",
    "# feature 10: Union Neighbours(out) of A and B\n",
    "def unionNeighbours(a, b, graph):\n",
    "    neighbours_a = getNeighbors(a, graph)\n",
    "    neighbours_b = getNeighbors(b, graph)\n",
    "    return len(neighbours_a.union(neighbours_b))\n",
    "\n",
    "'''\n",
    "##中介邻居特征\n",
    "'''\n",
    "# feature 11: Union Out of A and In of B\n",
    "def unionAoutBin(a, b, graph):\n",
    "    out_a = getDegreeOut(a, graph)\n",
    "    in_b = getDegreeIn(b, graph)\n",
    "    return len(out_a.union(in_b))\n",
    "\n",
    "'''\n",
    "##优先链接特征\n",
    "'''\n",
    "# feature 12: Product Neighbours of A and Neighbours of B\n",
    "def productAneighboursBneighbours(a, b, graph):\n",
    "    score = len(getNeighbors(a,graph)) * len(getNeighbors(b,graph))\n",
    "    return score\n",
    "\n",
    "'''\n",
    "##邻居评价特征\n",
    "'''\n",
    "# feature 13: all sum of edge exist between all neighbours of A and all neighbours of B\n",
    "def neighboursMeasure(a, b, graph):\n",
    "    neighbours_a = getNeighbors(a,graph)\n",
    "    neighbours_b = getNeighbors(b,graph)\n",
    "    score = 0\n",
    "    for each_a in neighbours_a:\n",
    "        for each_b in neighbours_b:\n",
    "            if(each_a == each_b or (each_a,each_b) in edge_set or (each_b,each_a) in edge_set):\n",
    "                score+=1\n",
    "    return score\n",
    "\n",
    "'''\n",
    "##反向关系特征\n",
    "'''\n",
    "# feature 14: all sum of edge exist between all neighbours of A and all neighbours of B\n",
    "def oppsiteDirection(a, b, graph):\n",
    "    score = 0\n",
    "    if (b,a) in edge_set:\n",
    "        score = 1\n",
    "    return score\n",
    "\n",
    "\n",
    "'''\n",
    "##邻居子图特征\n",
    "'''\n",
    "# feature 15: Subgraph of neighbours 1\n",
    "def neighboursSubgraph1(a, b, graph):\n",
    "    neighbours_a = getNeighbors(a,graph)\n",
    "    neighbours_b = getNeighbors(b,graph)\n",
    "    neighbours = list(neighbours_a.intersection(neighbours_b))\n",
    "    score = 0\n",
    "    for each_a in neighbours:\n",
    "        for each_b in neighbours:\n",
    "            if((each_a,each_b) in edge_set):\n",
    "                score+=1\n",
    "    return score\n",
    "\n",
    "# feature 16: Subgraph of neighbours 2\n",
    "def neighboursSubgraph2(a, b, graph):\n",
    "    neighbours_a = getNeighbors(a,graph)\n",
    "    neighbours_b = getNeighbors(b,graph)\n",
    "    neighbours = neighbours_a.intersection(neighbours_b)\n",
    "    neighbours.add(a)\n",
    "    neighbours.add(b)\n",
    "    neighbours = list(neighbours)\n",
    "    score = 0\n",
    "    for each_a in neighbours:\n",
    "        for each_b in neighbours:\n",
    "            if((each_a,each_b) in edge_set):\n",
    "                score+=1\n",
    "    return score\n",
    "\n",
    "\n",
    "# feature 17\n",
    "def GetJaccardCoefficient(user_X,user_y,graph):\n",
    "    neighbors_x = getNeighbors(user_X, graph)\n",
    "    neighbors_y = getNeighbors(user_y, graph)\n",
    "    CommonNeighbors=len(neighbors_x.intersection(neighbors_y))\n",
    "    AllNeighborss=len(neighbors_x.union(neighbors_y))\n",
    "    JaccardCoefficient=0\n",
    "    if AllNeighborss>0:\n",
    "        JaccardCoefficient=CommonNeighbors/AllNeighborss\n",
    "    return JaccardCoefficient\n",
    "\n",
    "#feature 18 Adamic\n",
    "#邻居的邻居数量越少，就越凸显它作为“中间人”的重要性，毕竟一共只认识那么少人，却恰好是x，y的好朋友\n",
    "\n",
    "def GetAdamic(user_X,user_y,graph):\n",
    "    neighbors_x = getNeighbors(user_X, graph)\n",
    "    neighbors_y = getNeighbors(user_y, graph)\n",
    "    CommonNeighbors=neighbors_x.intersection(neighbors_y)\n",
    "    Adamic=0\n",
    "    for commonNeighbor in CommonNeighbors:\n",
    "        NeighborOfCommonNeighbor=len(getNeighbors(commonNeighbor,graph))\n",
    "        if NeighborOfCommonNeighbor!=0 and NeighborOfCommonNeighbor!=1:\n",
    "            Adamic+=1/math.log(NeighborOfCommonNeighbor)\n",
    "\n",
    "    return Adamic\n",
    "\n",
    "#feature 19\n",
    "#sumCoauthor\n",
    "def GetSumConeighbor(user_X,user_y,graph):\n",
    "    print(\"19\")\n",
    "    neighbors_x = getNeighbors(user_X, graph)\n",
    "    neighbors_y = getNeighbors(user_y, graph)\n",
    "    SumCoNeighbor=0\n",
    "    for Neighbor in neighbors_x:\n",
    "        print(\"a\")\n",
    "        NeighborOfNeighbor=len(getNeighbors(Neighbor,graph))\n",
    "        if NeighborOfNeighbor==1:\n",
    "            SumCoNeighbor+=1\n",
    "    for Neighbor in neighbors_y:\n",
    "        print(\"b\")\n",
    "        NeighborOfNeighbor=len(getNeighbors(Neighbor,graph))\n",
    "        if NeighborOfNeighbor==1:\n",
    "            SumCoNeighbor+=1\n",
    "    print(\"20\")\n",
    "    return SumCoNeighbor"
   ],
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "debugging methods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "def getFeatures(record: list) -> list:\n",
    "    node = [record[0],\n",
    "            productAneighboursBneighbours(record[1],record[-1],graph),\n",
    "            neighboursMeasure(record[1],record[-1],graph),\n",
    "            oppsiteDirection(record[1],record[-1],graph),\n",
    "            neighboursSubgraph1(record[1],record[-1],graph),\n",
    "            neighboursSubgraph2(record[1],record[-1],graph),\n",
    "            GetJaccardCoefficient(record[1],record[-1],graph),\n",
    "            GetAdamic(record[1],record[-1],graph)]\n",
    "    return node\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(validation_data))\n",
    "validation_data1 = validation_data[0:1000] + validation_data[10000:11000]\n",
    "print(len(validation_data1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "2000\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Feature Extraction for validation data\n",
    "validation_data1 = validation_data[0:10] + validation_data[100:110]\n",
    "\n",
    "features=[]\n",
    "for record in validation_data1:\n",
    "    features.append(getFeatures(record))\n",
    "\n",
    "title = [\"Id\", \"CommonNeighboursLevel1\"]\n",
    "test_pd = pd.DataFrame(columns=title, data=features)\n",
    "test_pd.to_csv('test_set_features_test.csv', encoding='utf-8')\n",
    "\n"
   ],
   "execution_count": 39,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "2 columns passed, passed data had 8 columns",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001B[0m in \u001B[0;36m_list_to_arrays\u001B[1;34m(data, columns, coerce_float, dtype)\u001B[0m\n\u001B[0;32m    563\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 564\u001B[1;33m         \u001B[0mcolumns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_validate_or_indexify_columns\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcontent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    565\u001B[0m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_convert_object_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcontent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcoerce_float\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcoerce_float\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001B[0m in \u001B[0;36m_validate_or_indexify_columns\u001B[1;34m(content, columns)\u001B[0m\n\u001B[0;32m    687\u001B[0m             \u001B[1;31m# caller's responsibility to check for this...\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 688\u001B[1;33m             raise AssertionError(\n\u001B[0m\u001B[0;32m    689\u001B[0m                 \u001B[1;34mf\"{len(columns)} columns passed, passed data had \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAssertionError\u001B[0m: 2 columns passed, passed data had 8 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-39-296bd7864689>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[0mtitle\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m\"Id\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"CommonNeighboursLevel1\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m \u001B[0mtest_pd\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtitle\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     12\u001B[0m \u001B[0mtest_pd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'test_set_features_test.csv'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'utf-8'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[0;32m    507\u001B[0m                     \u001B[1;32mif\u001B[0m \u001B[0mis_named_tuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mcolumns\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    508\u001B[0m                         \u001B[0mcolumns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_fields\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 509\u001B[1;33m                     \u001B[0marrays\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mto_arrays\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    510\u001B[0m                     \u001B[0mcolumns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mensure_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    511\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001B[0m in \u001B[0;36mto_arrays\u001B[1;34m(data, columns, coerce_float, dtype)\u001B[0m\n\u001B[0;32m    522\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m  \u001B[1;31m# columns if columns is not None else []\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    523\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 524\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_list_to_arrays\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcoerce_float\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcoerce_float\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    525\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mabc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mMapping\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    526\u001B[0m         return _list_of_dict_to_arrays(\n",
      "\u001B[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001B[0m in \u001B[0;36m_list_to_arrays\u001B[1;34m(data, columns, coerce_float, dtype)\u001B[0m\n\u001B[0;32m    565\u001B[0m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_convert_object_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcontent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcoerce_float\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcoerce_float\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    566\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mAssertionError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 567\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    568\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    569\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: 2 columns passed, passed data had 8 columns"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('4', '1', 1), ('4', '3', 1), ('4', '5', 1), ('2', '3', 1), ('1', '2', 1)]\n",
      "5\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}